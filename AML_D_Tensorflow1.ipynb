{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_DISCLAIMER : this is NOT a Tensorflow tutorial/course. Please find and follow one, after this appetizer!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create  a graph and run it in a TF session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One note on $reset\\_graph()$. It is common while experimenting (on either Jupyter notebooks or a py shell) to run the same commands many times: in this specific case (graphs), as a result you may end up with a default graph containing many duplicate nodes. One solution is to rerun the py shell or restart the jupyter kernel frequently. Pretty inconvenient. More convenient is to just reset the default graph by running\n",
    "\n",
    "    tf.reset_default_graph() \n",
    "\n",
    "or a more customized version, like the one below i.e.:\n",
    "\n",
    "    reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()   #note: I put it at the beginning of the cell, everytime I want to create a new graph from scratch\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(5)\n",
    "s = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I.e. \"tensor\" definition as **a piece of data that is flowing through a graph**: this is the reason behind the \"TF\" name, btw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is this graph? If you specify nothing, you are working on the \"default\" one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain a bit.\n",
    "\n",
    "A TensorFlow computation, in general, is represented as a dataflow Graph. A Graph contains a set of tf.Operation objects, which represent units of computation, and tf.Tensor objects, which represent the units of data that flow between operations. A default Graph is always registered, and accessible by calling tf.get_default_graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an operation to the default graph, simply call one of the functions that defines a new Operation. I.e. in building a computation graph, any node you create is automatically added to the default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()   #note: I put it at the beginning of the cell, everytime I want to create a new graph from scratch\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(5)\n",
    "s = a + b\n",
    "\n",
    "s.graph is tf.get_default_graph()\n",
    "#assert s.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another typical usage involves the $tf.Graph.as\\_default$ context manager, which overrides the current default graph for the lifetime of the context. \n",
    "\n",
    "(indeed, sometimes you want to manage multiple independent graphs: you can always create a new Graph and temporarily make it the default graph inside a $with$ block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_graph() \n",
    "\n",
    "my_graph = tf.Graph()\n",
    "with my_graph.as_default(): # i.e. \"using my_graph as the default graph, do as follows..\"\n",
    "    a = tf.constant(3)      # Define operations and tensors in `my_graph`.\n",
    "    b = tf.constant(5)\n",
    "    s = a + b\n",
    "    \n",
    "s.graph is my_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. because you are out of the context where 'my_graph' was the default graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try one more (in the default Graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")   # note: Variable with capital V\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note (for very precise people): tf.constant() is a node in the graph (ops), while tf.Variable() is a class. And in PEP8 python style guide \"Class names should normally use the CapWords convention\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code examples above (both) do not actually perform any computation. Each just creates a computation graph.\n",
    "\n",
    "In fact, not only the constants, but even the Variables are not initialized yet. \n",
    "\n",
    "Once you create a computation graph, next step is to evaluate it. To do so, you need to open a TF **session**, and in it you **initialize** the variables and **evaluate** the function (e.g. f as in the second example):\n",
    "\n",
    "* it is the TF session that takes care of placing the operations onto **devices** such as CPUs or GPUs and running them\n",
    "* it is the TF session that holds all the variables values (e.g. you need to close the session to free up resources)\n",
    "\n",
    "(_NOTE: in distributed-TF, this is on the servers, not on the session, though_)\n",
    "\n",
    "Let's see an example of code that creates a session, initializes the variables, evaluates f, then closes the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")   # note: Variable with capital V\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "\n",
    "print(result)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - but it is a bit cumbersome to have to repreat many $sess$ commands, and to need $sess.run()$ all times, so fortunately there is a better and cleaner way (context management):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")   # note: Variable with capital V\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, $f.eval()$ means that you are asking to \"_please evaluate the tensor f, i.e. run the whole graph (in a session, with variables initialised) to evaluate the tensor f_\". It is also quite clean, as the session dies as soon as you go out of the context ($with$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But.. do I really need to manually run the initializer once for every single variable I have? What if I have many?! Of course, there is neat way: you can use the $global\\_variables\\_initializer()$ function - see below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")   # note: Variable with capital V\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "init = tf.global_variables_initializer()   # prepare an init node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()                             # actually inizialize all variables\n",
    "    result = f.eval()\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it does not actually perform the initialization immediately, but rather it prepares an init node, i.e. creates a node in the graph that will initialize all variables when it is run (\"initialize to what\" was already specified in the computation graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that - of course - initialisation is needed only for Variables, not for constants. E.g. if I used the nodes as in the previous example, and I initialize it is fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(5)\n",
    "s = a + b\n",
    "\n",
    "init = tf.global_variables_initializer()   # prepare an init node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()                             # actually inizialize all variables\n",
    "    result = s.eval()\n",
    "    \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. but actually inizialisation was unnecessary, e.g. if I do not do it, it still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(5)\n",
    "s = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = s.eval()\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's recap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we are understanding that a TF piece of code is typically split into two parts:\n",
    "\n",
    "* **construction phase**: you build a computation graph\n",
    "* **execution phase**: you run it\n",
    "\n",
    "If you are using TF for ML (NOTE THAT TF IS NOT ONLY FOR ML!)\n",
    "\n",
    "* **construction phase**: you build a computation graph representing your ML model and the computations required to train it\n",
    "* **execution phase**: you run a loop that evaluates a training step repeatedly (e.g. one step per mini-batch), gradually improving the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifecycle of a node value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you evaluate a node, TF automatically determines the set of nodes that it depends on and it evaluates these nodes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "#init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "#    init.run()\n",
    "    print(y.eval())  # 10\n",
    "    print(z.eval())  # 15\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above:\n",
    "* reset\n",
    "* defines a very simple graph\n",
    "* starts a session\n",
    "* runs the graph to evaluate $y$\n",
    "* automatically detects that $y$ depends on $x$, which in turn depends on $w$, so it evaluates $w$, then $x$, then $y$ in this order, and then returns a value of $y$\n",
    "* runs the graph to evaluate $z$ (and again he needs first $w$ then $x$ to do so)\n",
    "\n",
    "Note that is does _not_ re-use the results of the previous calculation of $w$ and $x$: the preceding code evaluates $w$ and $x$ twice! BAD!\n",
    "\n",
    "**IMPORTANT: all node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs. A variable starts its life when its initializer is run, and it ends when the session is closed.**\n",
    "\n",
    "In order to evaluate $y$ and $z$ more efficiently, without evaluating $w$ and $x$ twice as in the preceding code block, you must ask TF to evaluate both $y$ and $z$ in just one graph run, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)  # 10\n",
    "    print(z_val)  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows TF to be flexible and evaluate only things upon requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: In single-process TensorFlow, multiple sessions do not share any state, even if they reuse the same graph (each session would have its own copy of every variable). In distributed TensorFlow, variable state is stored on the servers, not in the sessions, so multiple sessions can share the same variables._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a simple graph that calculates $ c = \\exp(\\sqrt 8 + 3) $. \n",
    "\n",
    "2. Now create a Session() and evaluate the operation that gives you the result of the equation above\n",
    "\n",
    "3. Create a graph that evaluates and prints both $ b = \\sqrt 8 $ and $ c = \\exp(\\sqrt 8 + 3) $. Try to implement this in a way that only evaluates $ \\sqrt 8 $ once.\n",
    "\n",
    "**Tip**: TensorFlow's API documentation is available at:\n",
    "https://www.tensorflow.org/versions/master/api_docs/python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try yourself in the cells above, and do not read below this line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "my_graph = tf.Graph()\n",
    "with my_graph.as_default():\n",
    "    c = tf.exp(tf.sqrt(tf.constant(8.)) + tf.constant(3.))\n",
    "    # actually, this also works:   c = tf.exp(tf.sqrt(8.) + 3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "my_graph = tf.Graph()\n",
    "with my_graph.as_default():\n",
    "    c = tf.exp(tf.sqrt(tf.constant(8.)) + tf.constant(3.))\n",
    "\n",
    "with tf.Session(graph=my_graph):\n",
    "    c_val = c.eval()\n",
    "\n",
    "c_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "my_graph = tf.Graph()\n",
    "with my_graph.as_default():\n",
    "    b = tf.sqrt(8.)\n",
    "    c = tf.exp(b + 3)\n",
    "    \n",
    "with tf.Session(graph=my_graph) as sess:\n",
    "    b_val, c_val = sess.run([b, c])\n",
    "    \n",
    "print(b_val)\n",
    "print(c_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: a working but WRONG implementation is below. It gives the right result, but it runs the graph twice, once to evaluate `b`, and once to evaluate `c`.  Since `c` depends on `b`, it means that `b` will be evaluated twice. Not what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WRONG!\n",
    "with tf.Session(graph=my_graph):\n",
    "    b_val = b.eval()  # evaluates b\n",
    "    c_val = c.eval()  # evaluates c, which means evaluating b again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## END OF THE EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and inspect your graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display your graph (not mandatory to understand all code in the next cell.. just run it.. NOTE it works only on Chrome..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def=None, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    graph_def = graph_def or tf.get_default_graph()\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "my_first_graph = tf.Graph()\n",
    "with my_first_graph.as_default():\n",
    "    b = tf.sqrt(8.)\n",
    "    c = tf.exp(b + 3)\n",
    "    \n",
    "with tf.Session(graph=my_first_graph) as sess:\n",
    "    b_val, c_val = sess.run([b, c])\n",
    "    \n",
    "print(b_val)\n",
    "print(c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graph(my_first_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try this second graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "my_second_graph = tf.get_default_graph()\n",
    "\n",
    "# construction\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "# execution\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_graph(my_second_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And re-try the same, as a third graph, with global variable initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "my_third_graph = tf.get_default_graph()\n",
    "\n",
    "# construction\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "# execution\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_graph(my_third_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TensorFlow operations (aka **ops**) can take any number of inputs and produce any number of outputs. E.g. the addition and multiplication ops each take two inputs and produce one output. Constants and variables take no input (they are called _source ops_). \n",
    "\n",
    "The inputs and outputs are multidimensional arrays that flow through the computation graph, called **tensors**. Just like NumPy arrays, tensors have a type and a shape (in the Python API, tensors are simply represented by NumPy ndarrays). They typically contain floats, but you can also use them to carry strings (arbitrary byte arrays)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
