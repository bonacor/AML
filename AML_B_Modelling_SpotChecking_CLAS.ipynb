{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-Checking Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot-checking as a \"lazy\" way of discovering which ML algos perform well on your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algorithm Spot-Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to spot-check, so the question now is NOT:\n",
    "\n",
    "    \"What algorithm should I ultimately use on my dataset?\"\n",
    "\n",
    "Instead it is:\n",
    "\n",
    "    \"What algorithms should I immediately spot-check on my dataset?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to take a look at 6 classification algorithms that you can spot-check on your dataset. \n",
    "\n",
    "Starting with 2 linear ML algorithms:\n",
    "\n",
    "* Logistic Regression\n",
    "* Linear Discriminant Analysis\n",
    "\n",
    "Then looking at 4 nonlinear ML algorithms:\n",
    "\n",
    "* k-Nearest Neighbors\n",
    "* Naive Bayes\n",
    "* Classification and Regression Trees\n",
    "* Support Vector Machines\n",
    "\n",
    "Each recipe is demonstrated on the diabetes dataset. A test harness using 10-fold cross-validation is used to demonstrate how to spot-check each ML algorithm. Mean accuracy measures are used to indicate algorithm performance. \n",
    "\n",
    "_DISCLAIMER: The recipes assume that you know about each ML algorithm, and more or less how to use them. We will not go into the API or parameterization of each algorithm. If you do not know, you still can proceed: just give some trust for now, and study more later!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression           # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76951469583\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classification\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct an LDA model using the LinearDiscriminantAnalysis class, which is documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis. LinearDiscriminantAnalysis.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis           # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773462064252\n"
     ]
    }
   ],
   "source": [
    "# LDA Classification\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearDiscriminantAnalysis()                           # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a KNN model using the KNeighborsClassifier class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier. html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier                           # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726555023923\n"
     ]
    }
   ],
   "source": [
    "# KNN Classification\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsClassifier()                           # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a Naive Bayes model using the GaussianNB class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB                           # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75517771702\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()                           # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a CART model using the DecisionTreeClassifier class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier. html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier                           # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.682194121668\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeClassifier()                           # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct an SVM model using the SVC class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC                           # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651025290499\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = SVC()                           # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did:\n",
    "\n",
    "* we discovered 6 ML algorithms that you can use to spot-check on your classification problem in Python using scikit-learn. Specifically, you learned how to spot-check 2 linear ML algorithms (Logistic Regression, Linear Discriminant Analysis) as well as how to spot-check 4 nonlinear algorithms (k-Nearest Neighbors, Naive Bayes, Classification and Regression Trees and Support Vector Machines)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now discover how you can use spot-checking on REGRESSION ML problems and practice with some different regression algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
