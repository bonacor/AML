{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-Checking Regression Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as we did for CLASSIFICATION algos, now for REGRESSION algos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we are going to take a look at 7 regression algorithms that you can spot-check on your dataset. We start with 4 linear ML algorithms:\n",
    "\n",
    "* Linear Regression\n",
    "* Ridge Regression\n",
    "* LASSO Linear Regression\n",
    "* Elastic Net Regression\n",
    "\n",
    "Then, we will look at 3 nonlinear ML algorithms:\n",
    "\n",
    "* k-Nearest Neighbors\n",
    "* Classification and Regression Trees\n",
    "* Support Vector Machines and Support Vector Regression\n",
    "\n",
    "Each recipe is demonstrated on the housing dataset. This is a regression problem where all attributes are numeric. A test harness with 10-fold cross-validation is used to demonstrate how to spot-check each ML algorithm. Mean squared error measures are used to indicate algorithm performance. \n",
    "\n",
    "NOTE: mean squared error values are inverted (negative). This is a quirk of the $cross_val_score()$ function used that requires all algorithm metrics to be sorted in ascending order (larger value is better). \n",
    "\n",
    "*DISCLAIMER: The recipes assume that you know about each ML algorithm and how to use them. We will not go into the API or parameterization of each algorithm.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a linear regression model using the LinearRegression class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression                              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.7052559445\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "filename = 'housing.data.csv'\n",
    "names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Linear Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()                              # <---\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a ridge regression model by using the Ridge class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge                              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.0782462093\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = Ridge()                              # <---\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a LASSO model by using the Lasso class [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso                              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.4640845883\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = Lasso()                              # <---\n",
    "scoring =  'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct an ElasticNet model using the ElasticNet class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet                              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-31.1645737142\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = ElasticNet()                              # <---\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct a KNN model for regression using the KNeighborsRegressor class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor. html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor                              # <--- note! Regressor now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-107.28683898\n"
     ]
    }
   ],
   "source": [
    "# KNN Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsRegressor()                              # <---\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a CART model for regression using the DecisionTreeRegressor class, documented [here](6http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor                              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-36.2850470588\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeRegressor()                              # <---\n",
    "scoring =  'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines and Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create an SVM model for regression using the SVR class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR                              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-91.0478243332\n"
     ]
    }
   ],
   "source": [
    "# SVM Regression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = SVR()                              # <---\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did:\n",
    "\n",
    "* we discovered how to spot-check ML algorithms for regression problems in Python using scikit-learn. Specifically, you learned about 4 linear machine learning algorithms (Linear Regression, Ridge Regression, LASSO Linear Regression and Elastic Net Regression) as well as 3 nonlinear algorithms (k-Nearest Neighbors, Classification and Regression Trees, SVM/SVR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to use classification and regression algorithms, you need to know how to compare the results of different algorithms to each other. We will now discover how to design simple experiments to directly compare ML algorithms to each other on your dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
