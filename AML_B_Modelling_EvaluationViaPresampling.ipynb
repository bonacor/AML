{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the performance of ML algos with Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is this _really_ needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See 'theory/intuition' lectures..\n",
    "\n",
    "We are going to look at 4 different techniques that we can use to split up our training dataset and create useful estimates of performance for our ML algorithms:\n",
    "\n",
    "1. Train and Test Sets\n",
    "1. k-fold Cross-Validation\n",
    "1. Leave One Out Cross-Validation\n",
    "1. Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussed in the lecture, and also in the hands-on.\n",
    "\n",
    "This algorithm evaluation technique is very fast. It has pros and cons:\n",
    "* _Pro_. It is ideal for large datasets (millions of records): splitting a large dataset into largish sub-datasets allows that that 1) each split of the data is **not too tiny**, and 2) both are **representative** of the underlying problem. Because of the speed, it is useful to use this approach when the algorithm you are investigating is slow to train. \n",
    "* _Con_. A downside of this technique is that it can have a **high variance**. This means that differences in the training and test dataset can result in meaningful differences in the estimate of accuracy.\n",
    "\n",
    "In the example below we split our dataset into 67%/33% splits for training and test and evaluate the accuracy of a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare for the evaluation with a train and test set\n",
    "test_size = 0.33\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.803%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()            # choose a model\n",
    "model.fit(X_train, Y_train)             # train on the training set\n",
    "result = model.score(X_test, Y_test)    # get accuracy as measured on the test set\n",
    "print(\"Accuracy: %.3f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Try to change the seed, and re-traing. Does accuracy change? Is it reproducible? Can you measure its variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What happens if I check accuracy on the _train_ set (conceptually wrong)? Do I see something different or not? What is the drawback if I do this mistake? (SOLUTION below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.405%\n"
     ]
    }
   ],
   "source": [
    "#seed = 8              ###QUIZ\n",
    "#test_size = 0.33      ###QUIZ \n",
    "# Evaluate using a train and a test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()            # choose a model\n",
    "model.fit(X_train, Y_train)             # train on the training set\n",
    "result = model.score(X_train, Y_train)    # get accuracy as measured on the train set now! (for the ###QUIZ)\n",
    "print(\"Accuracy: %.3f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussed in the hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score   # <---\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Leave One Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussed in the hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut       # <---\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.823% (42.196%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit      # <---\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.496% (1.698%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Shuffle Split Cross Validation\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, fine, but.. what techniques to use when?!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some tips to consider what resampling technique to use in different circumstances.\n",
    "\n",
    "* Generally k-fold cross-validation is the gold standard for evaluating the performance of a ML algorithm on unseen data with k set to 3, 5, or 10.\n",
    "\n",
    "* Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n",
    "\n",
    "* Techniques like leave-one-out cross-validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size.\n",
    "\n",
    "The best advice is to experiment and find a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did:\n",
    "\n",
    "* we discovered 4 statistical techniques that we can use to estimate the performance of ML algorithms, called Resampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see how you can evaluate the performance of classification and regression algorithms using a suite of different metrics and built in evaluation reports."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
